<!DOCTYPE html>
    <html>
    <head>
        <meta http-equiv="Content-type" content="text/html;charset=UTF-8">
        <title>Thoughts</title>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
        <link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <style>
.task-list-item { list-style-type: none; } .task-list-item-checkbox { margin-left: -20px; vertical-align: middle; }
</style>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        
        <script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>
    </head>
    <body>
        <h1 id="thoughts">Thoughts</h1>
<h2 id="scan-vs-random-access">Scan vs random access</h2>
<p>Really scan vs join.</p>
<h2 id="in-memory-vs-on-disk">In memory vs On disk</h2>
<p>Need not match, but minor DB changes should result in small on disk changes.</p>
<h3 id="addinsert">Add/Insert</h3>
<h3 id="delete">Delete</h3>
<h3 id="update">Update</h3>
<h2 id="dictionary-representation">Dictionary representation</h2>
<p>Must map</p>
<ul>
<li>Value → ID</li>
<li>ID → Value</li>
</ul>
<p>Fundamentally it's just a list of values, ID is the array index, but it's better if ID is invariate with the addition of new values, so either we scan for value, or we maintain an index of Value → ID</p>
<h3 id="dictionary-index">Dictionary index</h3>
<p>Simplest implementation would be to keep a sorted list of indices, but insertion of new values is expensive amd would requuire locking the entire index.
For a 1E6 unique entries that's ~3MB's of index.
This might not matter if the general case is that inserts do not add new dictionary entries.
Btree might be better, Another option is a sparse Array with room for insertion.</p>
<p>Another option is to use a sparse index to reduce the range that's scanned.
Idea here is to use a bit mask to reduce the ranges that need to be scanned likely based on low bitrange Hashes of the value. 128 bits reduces scans to upto 1% of the total volume.
However for randomly distributed data it's likely it's no help.</p>
<p>Simplest solution is to not have an index and always scan</p>
<h3 id="shared-dictionaries">Shared Dictionaries</h3>
<p>Ideally FK/PK pairs ould share the Dictionary.</p>
<p><strong>For variably sized values</strong><br>
List Ptr → value<br>
Ordered list of indices into above<br>
Values</p>
<p><strong>For fixed size values</strong><br>
List of Values<br>
Ordered list of indices into above<br></p>
<p>Note updates to the ordered list are likely to be monolithic, an column with 1M unique values would require updating ~20E6 bit or ~2.5 MB's of index. on average it's half that but still unpalatible.</p>
<p>One alternative is to use a page based index that generally doesn't cause ripples through the entire structure on insert, possibly a B* tree or PMA, or some cache aware/oblivious structure with pointers beween pages, but this will havve a memory overhead and an increased cost per lookup.</p>
<p>PMA's oare of the order of 2-4x bigger than the index. BTrees will be &lt; 2x</p>
<h2 id="column-vs-row-storage">Column vs Row storage</h2>
<h2 id="data-representations-for-none-fixed-size-fields">Data representations for none fixed size fields</h2>
<p>List of offsets, to actual data</p>
<h2 id="managing-deletes-and-updates">Managing deletes and updates</h2>
<h3 id="options">Options</h3>
<h4 id="insert-only">Insert Only</h4>
<p>Allows for potential timetravel data retrieval.<br>
Pathological for some usecases.</p>
<h4 id="update-in-place">Update in place</h4>
<h2 id="lock-granularirty">Lock granularirty</h2>
<h2 id="write">Write</h2>
<p>insert vs update</p>
<p>Transactions take all locks required at commit and modify.
Transaction is &quot;complete at the point&quot; the commit is in the log.</p>
<p>Shared state will in effect be a table lock on write commit (updating the index).
Unless there is no &quot;index&quot;.</p>
<h2 id="write-over-read">Write over Read</h2>
<p>Write transaction commit begins after Read start, and modifies data that will be read during read transaction.</p>
<ul>
<li>Since Write transaction could not have taken a lock on page already read in read transaction, read will complete as if write transaction had occurrred prior to the read transaction even if it started before.</li>
</ul>
<h2 id="read-over-write">Read over Write</h2>
<p>Not really an issue, write locks taken during commit process.</p>
<h2 id="table-snapshots-copy-on-write">Table snapshots (Copy on write)</h2>
<p>Table is a view of a base Read Only table (the snapshot), and an overlay.</p>
<p>Could alloew multiple overlays with some form of merge operation.</p>
<p>If scans are ordered this is a simple merge operation by &quot;Key&quot;. If scans are unordered requires scan of modifications, storing of keys and scan of parent with comparison to returned keys (i.e. requires an inmemory structure), could limit the size of this by forcing a complete copy from parent if modifications reach some threshold.</p>
<h2 id="compression">Compression</h2>
<p>Rely on compressed storage?</p>
<h2 id="encryption">Encryption</h2>
<p>Rely on encrypted storage?</p>
<h2 id="multiple-instances">Multiple instances</h2>
<h2 id="text-indexing">Text indexing</h2>
<ul>
<li>Word -&gt; ID</li>
<li>ID -&gt; Doc Array</li>
<li>/Doc -&gt; WID -&gt; tok offset</li>
<li>/Doc -&gt; tok array</li>
</ul>
<p>// Need to do analysis assuming 1% unique words <br>
Document with 100K works - say 1K unique words/doc 20K overall<br>
20000 * (48 bits per word + 16 bits / ID) = 1,280,000 bits<br>
-- someway to compute Id's from words?</p>
<p>1000 Documents<br>
1000 * (10 bits per doc ID) * 1000 = 10,000,000 bits</p>
<p>Doc -&gt; ID+Token<br>
words occur on average 100 times per doc<br>
1000 * (16 bits + 17 bits token offset * 100)*1000 = 1,716,000,000<br></p>
<p>Doc -&gt; tokenArray<br>
1000 * 100,000 * 16bits = 1,600,000,000<br>
-- could be extended to allow reconstruction of the document</p>
<p>Dominated by last 2 tables<br></p>
<table>
<thead>
<tr>
<th style="text-align:right">Bits</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">1,716,000,000</td>
</tr>
<tr>
<td style="text-align:right">1,600,000,000</td>
</tr>
<tr>
<td style="text-align:right">10,000,000</td>
</tr>
<tr>
<td style="text-align:right">1,280,000</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:right"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">3,327,280,000</td>
</tr>
</tbody>
</table>
<p>Total size = 415,910,000 Bytes<br>
Total Document size = 100,000 * 6 * 1000 = 600,000,000 Bytes</p>
<p>I would assume closer to 1:1 ratio given miscelaneous overhead.</p>
<p>Token array is not strictly necessary, it speeds up NGram resolution, without it.</p>
<table>
<thead>
<tr>
<th style="text-align:right">Bits</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">1,716,000,000</td>
</tr>
<tr>
<td style="text-align:right">10,000,000</td>
</tr>
<tr>
<td style="text-align:right">1,280,000</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:right"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">1,727,280,000</td>
</tr>
</tbody>
</table>
<p>Total size = 215,910,000 Bytes<br></p>
<p>Tending towards about 1/2 of document size.</p>

    </body>
    </html>